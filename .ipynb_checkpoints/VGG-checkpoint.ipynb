{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, './src')\n",
    "from crfrnn_model import get_crfrnn_model_def\n",
    "import util\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, ZeroPadding2D, \\\n",
    "    Dropout, Conv2DTranspose, Cropping2D, Add, UpSampling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder,image_color_mode = \"rgb\",\n",
    "                    mask_color_mode = \"rgb\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (500,500),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    mask_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = \"rgb\",\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        #img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        yield (img,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trainGenerator(1,'/Users/mavaylon/Research/Pytorch_UNet/Data/Talita/Talita_500x500','orig','gt',save_to_dir = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 500, 500, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 700, 700, 3)  0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 698, 698, 64) 1792        zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1_2 (Conv2D)                (None, 698, 698, 64) 36928       conv1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 349, 349, 64) 0           conv1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1 (Conv2D)                (None, 349, 349, 128 73856       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2 (Conv2D)                (None, 349, 349, 128 147584      conv2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 175, 175, 128 0           conv2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1 (Conv2D)                (None, 175, 175, 256 295168      pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2 (Conv2D)                (None, 175, 175, 256 590080      conv3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3 (Conv2D)                (None, 175, 175, 256 590080      conv3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 88, 88, 256)  0           conv3_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1 (Conv2D)                (None, 88, 88, 512)  1180160     pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2 (Conv2D)                (None, 88, 88, 512)  2359808     conv4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3 (Conv2D)                (None, 88, 88, 512)  2359808     conv4_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 44, 44, 512)  0           conv4_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1 (Conv2D)                (None, 44, 44, 512)  2359808     pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2 (Conv2D)                (None, 44, 44, 512)  2359808     conv5_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3 (Conv2D)                (None, 44, 44, 512)  2359808     conv5_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 22, 22, 512)  0           conv5_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fc6 (Conv2D)                    (None, 16, 16, 4096) 102764544   pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 16, 4096) 0           fc6[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc7 (Conv2D)                    (None, 16, 16, 4096) 16781312    dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 16, 4096) 0           fc7[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "score-fr (Conv2D)               (None, 16, 16, 2)    8194        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "score-pool4 (Conv2D)            (None, 44, 44, 2)    1026        pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "score2 (Conv2DTranspose)        (None, 34, 34, 2)    66          score-fr[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_12 (Cropping2D)      (None, 34, 34, 2)    0           score-pool4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 34, 34, 2)    0           score2[0][0]                     \n",
      "                                                                 cropping2d_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "score-pool3 (Conv2D)            (None, 88, 88, 2)    514         pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "score4 (Conv2DTranspose)        (None, 70, 70, 2)    64          add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_13 (Cropping2D)      (None, 70, 70, 2)    0           score-pool3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 70, 70, 2)    0           score4[0][0]                     \n",
      "                                                                 cropping2d_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "upsample (Conv2DTranspose)      (None, 568, 568, 2)  1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_14 (Cropping2D)      (None, 500, 500, 2)  0           upsample[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "crfrnn (CrfRnnLayer)            (1, 500, 500, 2)     12          cropping2d_14[0][0]              \n",
      "                                                                 input_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 134,271,444\n",
      "Trainable params: 134,271,444\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from crfrnn_layer import CrfRnnLayer\n",
    "from keras.models import Model\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "\n",
    "\"\"\" Returns Keras CRN-RNN model definition.\n",
    "\n",
    "Currently, only 500 x 500 images are supported. However, one can get this to\n",
    "work with different image sizes by adjusting the parameters of the Cropping2D layers\n",
    "below.\n",
    "\"\"\"\n",
    "\n",
    "channels, height, width = 3, 500, 500\n",
    "\n",
    "n_classes = 2 #21\n",
    "\n",
    "# Input\n",
    "input_shape = (height, width, 3)\n",
    "img_input = Input(shape=input_shape)\n",
    "\n",
    "# Add plenty of zero padding\n",
    "x = ZeroPadding2D(padding=(100, 100))(img_input)\n",
    "\n",
    "# VGG-16 convolution block 1\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='valid', name='conv1_1')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "# VGG-16 convolution block 2\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_1')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2', padding='same')(x)\n",
    "\n",
    "# VGG-16 convolution block 3\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3', padding='same')(x)\n",
    "pool3 = x\n",
    "\n",
    "# VGG-16 convolution block 4\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool4', padding='same')(x)\n",
    "pool4 = x\n",
    "\n",
    "# VGG-16 convolution block 5\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='pool5', padding='same')(x)\n",
    "\n",
    "# Fully-connected layers converted to convolution layers\n",
    "x = Conv2D(4096, (7, 7), activation='relu', padding='valid', name='fc6')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(4096, (1, 1), activation='relu', padding='valid', name='fc7')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(n_classes, (1, 1), padding='valid', name='score-fr')(x)\n",
    "\n",
    "# Deconvolution\n",
    "score2 = Conv2DTranspose(n_classes, (4, 4), strides=2, name='score2')(x)\n",
    "\n",
    "# Skip connections from pool4\n",
    "score_pool4 = Conv2D(n_classes, (1, 1), name='score-pool4')(pool4)\n",
    "score_pool4c = Cropping2D((5, 5))(score_pool4)\n",
    "score_fused = Add()([score2, score_pool4c])\n",
    "score4 = Conv2DTranspose(n_classes, (4, 4), strides=2, name='score4', use_bias=False)(score_fused)\n",
    "\n",
    "# Skip connections from pool3\n",
    "score_pool3 = Conv2D(n_classes, (1, 1), name='score-pool3')(pool3)\n",
    "score_pool3c = Cropping2D((9, 9))(score_pool3)\n",
    "\n",
    "# Fuse things together\n",
    "score_final = Add()([score4, score_pool3c])\n",
    "\n",
    "# Final up-sampling and cropping\n",
    "upsample = Conv2DTranspose(n_classes, (16, 16), strides=8, name='upsample', use_bias=False)(score_final)\n",
    "upscore = Cropping2D(((31, 37), (31, 37)))(upsample)\n",
    "\n",
    "output = CrfRnnLayer(image_dims=(height, width),\n",
    "                     num_classes=n_classes,\n",
    "                     theta_alpha=160.,\n",
    "                     theta_beta=3.,\n",
    "                     theta_gamma=3.,\n",
    "                     num_iterations=10,\n",
    "                     name='crfrnn')([upscore, img_input])\n",
    "model = Model(inputs = img_input, outputs = output)\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "model.summary()\n",
    "# Build the model\n",
    "#model_crfrnn = Model(img_input, output)\n",
    "#model_crfrnn = get_segmentation_model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 images belonging to 1 classes.\n",
      "Found 512 images belonging to 1 classes.\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Incompatible shapes: [1,500,500,3] vs. [1,500,500,2]\n\t [[node gradient_tape/binary_crossentropy/mul/BroadcastGradientArgs (defined at <ipython-input-23-7cf2f6f1336d>:1) ]] [Op:__inference_train_function_10542]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7cf2f6f1336d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [1,500,500,3] vs. [1,500,500,2]\n\t [[node gradient_tape/binary_crossentropy/mul/BroadcastGradientArgs (defined at <ipython-input-23-7cf2f6f1336d>:1) ]] [Op:__inference_train_function_10542]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(data,steps_per_epoch=256,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/512 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n",
      "The pixel values of the segmentation image /Users/mavaylon/Research/Pytorch_UNet/Data/Talita/Talita_500x500/gt/image_408.png violating range [0, 1]. Found maximum pixel value 255\n",
      "Dataset not verified!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-50103bef63e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_crfrnn.train(train_images = \"/Users/mavaylon/Research/Pytorch_UNet/Data/Talita/Talita_500x500/orig/\", \n\u001b[1;32m      2\u001b[0m             \u001b[0mtrain_annotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/Users/mavaylon/Research/Pytorch_UNet/Data/Talita/Talita_500x500/gt/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m             epochs=5)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras_segmentation/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_images, train_annotations, input_height, input_width, n_classes, verify_dataset, checkpoints_path, epochs, batch_size, validate, val_images, val_annotations, val_batch_size, auto_resume_checkpoint, load_weights, steps_per_epoch, val_steps_per_epoch, gen_use_multiprocessing, ignore_zero_class, optimizer_name, do_augment, augmentation_name)\u001b[0m\n\u001b[1;32m    131\u001b[0m                                                \u001b[0mtrain_annotations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                                                n_classes)\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mverified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Verifying validation dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_crfrnn.train(train_images = \"/Users/mavaylon/Research/Pytorch_UNet/Data/Talita/Talita_500x500/orig/\", \n",
    "            train_annotations=\"/Users/mavaylon/Research/Pytorch_UNet/Data/Talita/Talita_500x500/gt/\",\n",
    "            epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.1.2\n",
      "  Downloading Keras-2.1.2-py2.py3-none-any.whl (304 kB)\n",
      "\u001b[K     |████████████████████████████████| 304 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /Users/mavaylon/opt/anaconda3/lib/python3.7/site-packages (from keras==2.1.2) (1.18.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/mavaylon/opt/anaconda3/lib/python3.7/site-packages (from keras==2.1.2) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/mavaylon/opt/anaconda3/lib/python3.7/site-packages (from keras==2.1.2) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /Users/mavaylon/opt/anaconda3/lib/python3.7/site-packages (from keras==2.1.2) (5.3)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
